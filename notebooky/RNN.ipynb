{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train_data = pd.read_csv(\"testy/toxic_eng/train.csv\")\n",
    "test_data = pd.read_csv(\"testy/toxic_eng/test.csv\")\n",
    "\n",
    "if \"toxic\" not in train_data.columns or \"toxic\" not in test_data.columns:\n",
    "    raise ValueError(\"Missing 'toxic' column in the dataset!\")\n",
    "\n",
    "max_words = 20000  \n",
    "max_length = 128   \n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_data['comment_text'])\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train_data['comment_text'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data['comment_text'])\n",
    "\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "train_labels = np.array(train_data['toxic'])  \n",
    "test_labels = np.array(test_data['toxic'])\n",
    "\n",
    "\n",
    "\n",
    "# v tomto pripade sme sigmoid dali preto lebo ide o binarnu klasifikaciu\n",
    "model = Sequential([\n",
    "    Embedding(max_words, 128, input_length=max_length),\n",
    "    SimpleRNN(128, return_sequences=False),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation=\"sigmoid\")  \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(train_padded, train_labels, validation_data=(test_padded, test_labels), epochs=10, batch_size=32)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_padded, test_labels)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "model.save(\"final_rnn_model_tf.keras\")\n",
    "print(\"ulozime model do> final_rnn_model_tf.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred = model.predict(test_padded)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)  \n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(test_labels, y_pred_binary)\n",
    "recall = recall_score(test_labels, y_pred_binary)\n",
    "f1 = f1_score(test_labels, y_pred_binary)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
